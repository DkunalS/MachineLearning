{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec10a81-f1ba-485c-b3d7-450c846db9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a8cb48-9376-471b-90d9-08bb44fdc9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'ID': 249, 'type': 'NATIVE', 'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkovič', 'venue': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "car_evaluation = fetch_ucirepo(id=19) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = car_evaluation.data.features \n",
    "y = car_evaluation.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(car_evaluation.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(car_evaluation.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab297b-5961-49de-b886-aca581747e20",
   "metadata": {},
   "source": [
    "# DataSet car_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9617d27d-8801-4730-8f4d-1509971c2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52a38f62-faf0-495e-b585-139c09034c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 81.1+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0133d5d4-c47c-4286-9b2a-95b83f7e5c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ef97d9a-4970-4a66-b857-916f44976441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    1210\n",
       "1     518\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class'] = np.where(y['class']=='unacc',0,1)\n",
    "y['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aab658eb-352c-4198-8f10-e7337de601ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8529edd0-296d-4bbb-b27b-ff1760854499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=24,test_size=0.3,stratify=y['class'])\n",
    "# in `train_test_split` use `statify='classname'` to make near about y_test, y_train to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aae9eb08-65ef-43cf-b70a-0e6d029100f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore').set_output(transform='pandas')\n",
    "X_trn_ohe = ohe.fit_transform(X_train)\n",
    "X_tst_ohe = ohe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ce48ff-2977-46fc-bdc7-7ab698e5806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f37b0202-5c63-4868-b52b-eecfe3e90e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9633911368015414\n",
      "[[355   8]\n",
      " [ 11 145]]\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "X_trn_log = log.fit(X_trn_ohe,y_train)\n",
    "y_pred = log.predict(X_tst_ohe)\n",
    "print(accuracy_score(y_test['class'],y_pred))     # Bcuz of using 'statify' the accuray score will increase 94% to 96%\n",
    "print(confusion_matrix(y_test['class'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05449d60-906b-44cc-aaae-0d25fe816923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0    70.023148\n",
       "1    29.976852\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find parcentage of [y] : unacc, acc, good, verygood\n",
    "y['class'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2651b64a-78a0-400d-aa46-05b8beffd431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      " class\n",
      "0    70.057899\n",
      "1    29.942101\n",
      "Name: proportion, dtype: float64\n",
      "------------------------------------\n",
      "y_test class\n",
      "0    69.942197\n",
      "1    30.057803\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# To find parcentage of [ y_train, y_test]\n",
    "print(\"y_train\\n\",y_train['class'].value_counts(normalize=True)*100)\n",
    "print('------------------------------------')\n",
    "print(\"y_test\",y_test['class'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c2607-99ae-4796-8819-8e1c9b030466",
   "metadata": {},
   "source": [
    "- Sample should represent the correctly\n",
    "- in `train_test_split` use `statify='classname'` to make near about y_test, y_train to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d988f64-f72c-44bf-a05f-e66d24653496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e1c34bf-0251-4a5a-8551-60b50e02772f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "1210*0.7\n",
    "1210*70.02/100\n",
    "1210-847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82c6791a-9e00-4172-90cd-b5e844ec5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "518*0.7\n",
    "518*29.94/100\n",
    "518-155"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd3572-723d-4fdc-9d5e-b528815291a9",
   "metadata": {},
   "source": [
    "# Parameters:\n",
    "**penalty{‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’ :**\n",
    "- Specify the norm of the penalty:\n",
    "    1. None: no penalty is added;\n",
    "    2. 'l2': add a L2 penalty term and it is the default choice;\n",
    "    3. 'l1': add a L1 penalty term;\n",
    "    4. 'elasticnet': both L1 and L2 penalty terms are added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e67785-ab04-4274-b85a-edf058713187",
   "metadata": {},
   "source": [
    "- **Multi-Class:**\n",
    "    1. Multinominal : (also know an softmax)\n",
    "    2. OVR (One v/s Rest of All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf83f76b-001f-401d-a79d-2faf36f36057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa0db289-0fc1-40ce-bcd5-b3171b9b1fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOG__solver': 'lbfgs'}\n",
      "0.8303409566892854\n"
     ]
    }
   ],
   "source": [
    "# multi_class='multinomial'\n",
    "\n",
    "ohe = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "log = LogisticRegression(multi_class='multinomial')    # write multi_class='multinomial' bcuz if it not written it takes OVE (one v/s Rest of All) \n",
    "pipe = Pipeline([('OHE',ohe),('LOG',log)])\n",
    "# they are parameters of Logistic Regression class so used \n",
    "params = {\n",
    "    'LOG__solver':['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']\n",
    "}\n",
    "gcv = GridSearchCV(pipe, param_grid=params)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa9934a0-40d1-4331-8732-ce49c3332bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOG__solver': 'newton-cg'}\n",
      "0.829761246544358\n"
     ]
    }
   ],
   "source": [
    "# multi_class='ovr'\n",
    "ohe = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "log = LogisticRegression(multi_class='ovr')    # write multi_class='multinomial' bcuz if it not written it takes OVE (one v/s Rest of All) \n",
    "pipe = Pipeline([('OHE',ohe),('LOG',log)])\n",
    "# they are parameters of Logistic Regression class so used \n",
    "params = {\n",
    "    'LOG__solver':['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']\n",
    "}\n",
    "gcv = GridSearchCV(pipe, param_grid=params)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af4edcf5-c7ac-472f-a4ff-72592c217168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOG__C': np.float64(2.6323157894736844), 'LOG__multi_class': 'ovr', 'LOG__solver': 'lbfgs'}\n",
      "0.9502370779927956\n"
     ]
    }
   ],
   "source": [
    "# Automatically Select best \n",
    "ohe = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "log = LogisticRegression(random_state=24)    # write multi_class='multinomial' bcuz if it not written it takes OVE (one v/s Rest of All) \n",
    "kfold = StratifiedKFold(n_splits=5, random_state=24, shuffle=True)\n",
    "pipe = Pipeline([('OHE',ohe),('LOG',log)])\n",
    "# they are parameters of Logistic Regression class so used \n",
    "params = {\n",
    "    'LOG__solver':['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga'],\n",
    "    'LOG__multi_class':['ovr','multinominal'],\n",
    "    'LOG__C':np.linspace(0.001,10,20)\n",
    "}\n",
    "gcv = GridSearchCV(pipe, param_grid=params,cv=kfold)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "042418d3-1895-499b-898b-6f45f964f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 16)\n"
     ]
    }
   ],
   "source": [
    "pd_cv = pd.DataFrame(gcv.cv_results_)\n",
    "print(pd_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a485f9-0ce6-4564-9b54-393f9a186b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
